{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging in PLAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAMS has built-in logging which aims to simplify tracking the progress and status of jobs. This consists of progress logging to stdout and a logfile, and writing job summaries to CSV files. Each of these is explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAMS writes job progress to stdout and a plain text logfile. The location of this logfile is determined by the working directory of the default job manager. \n",
    "\n",
    "Users can also write logs to the same locations using the `log` function. This takes a `level` argument. By convention in PLAMS, the level should be between 0-7, with 0 being the most and 7 the least important logging.\n",
    "\n",
    "The level of logging that is written to stdout and the logfile can be changed through the `config.LogSettings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scm.plams import Settings, AMSJob, from_smiles, log, config\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "def get_test_job():\n",
    "    global counter\n",
    "    s = Settings()\n",
    "    s.input.ams.Task = \"SinglePoint\"\n",
    "    s.input.dftb\n",
    "    counter += 1\n",
    "    return AMSJob(name=f\"test{counter}\", molecule=from_smiles(\"C\"), settings=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.log.stdout = 3\n",
    "config.log.file = 5\n",
    "config.jobmanager.hashing = None  # Force PLAMS to re-run identical test jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.11|09:43:00] JOB test1 STARTED\n",
      "[28.11|09:43:00] JOB test1 RUNNING\n",
      "[28.11|09:43:01] JOB test1 FINISHED\n",
      "[28.11|09:43:01] JOB test1 SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "job = get_test_job()\n",
    "job.run()\n",
    "log(\"Test job finished\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.11|09:43:00] Starting test1.prerun()\n",
      "[28.11|09:43:00] test1.prerun() finished\n",
      "[28.11|09:43:00] JOB test1 RUNNING\n",
      "[28.11|09:43:00] Executing test1.run\n",
      "[28.11|09:43:01] Execution of test1.run finished with returncode 0\n",
      "[28.11|09:43:01] JOB test1 FINISHED\n",
      "[28.11|09:43:01] Starting test1.postrun()\n",
      "[28.11|09:43:01] test1.postrun() finished\n",
      "[28.11|09:43:01] JOB test1 SUCCESSFUL\n",
      "[28.11|09:43:01] Test job finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(config.default_jobmanager.logfile, \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the logs from an AMS calculation can also be forwarded to the progress logs using the `watch = True` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.11|09:43:01] JOB test2 STARTED\n",
      "[28.11|09:43:01] JOB test2 RUNNING\n",
      "[28.11|09:43:01] test2: AMS 2024.206  RunTime: Nov28-2024 09:43:01  ShM Nodes: 1  Procs: 6\n",
      "[28.11|09:43:02] test2: DFTB: SCC cycle\n",
      "[28.11|09:43:02] test2: cyc=  1 err=1.1E+00 method=1 nvec= 1 mix=0.075 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc=  2 err=1.1E+00 method=1 nvec= 1 mix=0.154 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc=  3 err=8.9E-01 method=1 nvec= 2 mix=0.201 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc=  4 err=1.7E-02 method=1 nvec= 3 mix=0.207 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc=  5 err=6.8E-03 method=1 nvec= 4 mix=0.213 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc=  6 err=2.6E-03 method=1 nvec= 5 mix=0.219 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc=  7 err=7.2E-05 method=1 nvec= 6 mix=0.226 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc=  8 err=6.8E-05 method=1 nvec= 1 mix=0.233 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc=  9 err=4.2E-05 method=1 nvec= 2 mix=0.240 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc= 10 err=6.2E-07 method=1 nvec= 3 mix=0.247 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc= 11 err=5.8E-08 method=1 nvec= 3 mix=0.254 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc= 12 err=3.6E-08 method=1 nvec= 4 mix=0.262 e=    0.0000\n",
      "[28.11|09:43:02] test2: cyc= 13 err=9.0E-11 method=1 nvec= 4 mix=0.270 e=    0.0000\n",
      "[28.11|09:43:02] test2: SCC cycle converged!\n",
      "[28.11|09:43:02] test2: NORMAL TERMINATION\n",
      "[28.11|09:43:02] JOB test2 FINISHED\n",
      "[28.11|09:43:02] JOB test2 SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "job = get_test_job()\n",
    "job.run(watch=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Summary Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAMS also writes summaries of jobs to a CSV file, the location of which by default is also determined by the job manager. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.11|09:43:02] JOB parent_job STARTED\n",
      "[28.11|09:43:02] JOB parent_job RUNNING\n",
      "[28.11|09:43:02] JOB parent_job/test3 STARTED\n",
      "[28.11|09:43:02] JOB parent_job/test3 RUNNING\n",
      "[28.11|09:43:03] JOB parent_job/test3 FINISHED\n",
      "[28.11|09:43:03] JOB parent_job/test3 SUCCESSFUL\n",
      "[28.11|09:43:03] JOB parent_job/test4 STARTED\n",
      "[28.11|09:43:03] JOB parent_job/test4 RUNNING\n",
      "[28.11|09:43:04] JOB parent_job/test4 FINISHED\n",
      "[28.11|09:43:04] JOB parent_job/test4 SUCCESSFUL\n",
      "[28.11|09:43:04] JOB parent_job/test5 STARTED\n",
      "[28.11|09:43:04] JOB parent_job/test5 RUNNING\n",
      "[28.11|09:43:11] WARNING: Job test5 finished with nonzero return code\n",
      "[28.11|09:43:11] WARNING: Main KF file ams.rkf not present in /path/plams/examples/LoggingExamples/plams_workdir/parent_job/test5\n",
      "[28.11|09:43:11] JOB parent_job/test5 CRASHED\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] Obtaining results of test5 failed. Returned value is None\n",
      "[28.11|09:43:11] Obtaining results of test5 successful. However, no guarantee that they make sense\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] Obtaining results of test5 failed. Returned value is None\n",
      "[28.11|09:43:11] Obtaining results of test5 successful. However, no guarantee that they make sense\n",
      "[28.11|09:43:11] Could not read termination status from file None\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] Obtaining results of test5 failed. Returned value is None\n",
      "[28.11|09:43:11] Obtaining results of test5 successful. However, no guarantee that they make sense\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] Obtaining results of test5 failed. Returned value is None\n",
      "[28.11|09:43:11] Obtaining results of test5 successful. However, no guarantee that they make sense\n",
      "[28.11|09:43:11] Could not read termination status from file None\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] Obtaining results of test5 failed. Returned value is None\n",
      "[28.11|09:43:11] Obtaining results of test5 successful. However, no guarantee that they make sense\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] WARNING: Trying to obtain results of crashed or failed job test5\n",
      "[28.11|09:43:11] Obtaining results of test5 successful. However, no guarantee that they make sense\n",
      "[28.11|09:43:11] Obtaining results of test5 successful. However, no guarantee that they make sense\n",
      "[28.11|09:43:11] JOB parent_job FINISHED\n",
      "[28.11|09:43:11] JOB parent_job FAILED\n"
     ]
    }
   ],
   "source": [
    "from scm.plams import MultiJob\n",
    "\n",
    "\n",
    "multi_job = MultiJob(name=\"parent_job\", children=[get_test_job() for _ in range(3)])\n",
    "multi_job.children[2].settings.input.ams.Task = \"Not a task!\"\n",
    "multi_job.run();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These CSVs give overall information on the status of all jobs run by a given job manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     job_name  job_status  job_ok  \\\n",
      "0       test1  successful    True   \n",
      "1       test2  successful    True   \n",
      "2       test3  successful    True   \n",
      "3       test4  successful    True   \n",
      "4       test5     crashed   False   \n",
      "5  parent_job      failed   False   \n",
      "\n",
      "                                    job_get_errormsg  \n",
      "0                                                NaN  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3                                                NaN  \n",
      "4  Input error: value \"Not a task!\" found in line...  \n",
      "5                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(config.default_jobmanager.job_logger.logfile)\n",
    "    print(df[[\"job_name\", \"job_status\", \"job_ok\", \"job_get_errormsg\"]])\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Loggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAMS also provides access to text and csv loggers for use in your workflows. These are obtained with the `get_logger` method. Loggers need to be set up with the `configure` method, which determines which file to write to and whether to write to stdout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.11|09:43:12] I want to log this to a separate file!\n",
      "\n",
      "molecule,short_name\n",
      "Acetylacetonate,acac\n",
      "Ethylenediaminetetraaceticacid acid,EDTA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scm.plams import get_logger\n",
    "\n",
    "my_text_logger = get_logger(\"my_text_logger\", \"txt\")\n",
    "my_csv_logger = get_logger(\"my_csv_logger\", \"csv\")\n",
    "\n",
    "my_text_logger.configure(logfile_level=3, logfile_path=\"./my_text_logger.txt\", include_date=True, include_time=True)\n",
    "my_csv_logger.configure(logfile_level=3, logfile_path=\"./my_csv_logger.csv\")\n",
    "\n",
    "my_text_logger.log(\"I want to log this to a separate file!\", 3)\n",
    "my_csv_logger.log({\"molecule\": \"Acetylacetonate\", \"short_name\": \"acac\"}, 3)\n",
    "my_csv_logger.log({\"molecule\": \"Ethylenediaminetetraaceticacid acid\", \"short_name\": \"EDTA\"}, 3)\n",
    "\n",
    "with open(my_text_logger.logfile) as f:\n",
    "    print(f.read())\n",
    "\n",
    "with open(my_csv_logger.logfile) as f:\n",
    "    print(f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
